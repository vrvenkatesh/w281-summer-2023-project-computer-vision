{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1p8wbonrBoLl"
   },
   "source": [
    "# Fruit and Vegetable Classification\n",
    "## \\# Class activation heatmap for image classification\n",
    "Taken from: https://www.kaggle.com/code/databeru/fruit-and-vegetable-classification\n",
    "\n",
    "## \\# Grad-CAM class activation visualization\n",
    "\n",
    "Having 3861 images of 36 different fruits/vegetables\n",
    "\n",
    "![fruit vegetable](https://i.imgur.com/KUAcIQD.jpeg)\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/MichaelTay/w281-summer-2023-project/blob/main/baseline.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KaL5HEJPBoLn"
   },
   "source": [
    "<h1>Table of contents</h1>\n",
    "\n",
    "\n",
    "<ul>\n",
    "<li><a href=\"#1\"><strong>1. Loading and preprocessing</strong></a>\n",
    "</ul>\n",
    "    \n",
    "<ul>\n",
    "<li><a href=\"#2\"><strong>2. Load the Images with a generator and Data Augmentation</strong></a>\n",
    "</ul>\n",
    "\n",
    "<ul>\n",
    "<li><a href=\"#3\"><strong>3. Train the model</strong></a>\n",
    "</ul>\n",
    "\n",
    "<ul>\n",
    "<li><a href=\"#4\"><strong>4. Visualize the result</strong></a>\n",
    "</ul>\n",
    "\n",
    "<ul>\n",
    "<li><a href=\"#5\"><strong>5. Class activation heatmap for image classification</strong></a>\n",
    "</ul>\n",
    "\n",
    "# Context\n",
    "\n",
    "This dataset contains images of the following food items:\n",
    "\n",
    "- **fruits**: banana, apple, pear, grapes, orange, kiwi, watermelon, pomegranate, pineapple, mango\n",
    "- **vegetables**: cucumber, carrot, capsicum, onion, potato, lemon, tomato, raddish, beetroot, cabbage, lettuce, spinach, soy bean, cauliflower, bell pepper, chilli pepper, turnip, corn, sweetcorn, sweet potato, paprika, jalepeño, ginger, garlic, peas, eggplant\n",
    "\n",
    "# Content\n",
    "This dataset contains three folders:\n",
    "\n",
    "- train (100 images each)\n",
    "- test (10 images each)\n",
    "- validation (10 images each)\n",
    "each of the above folders contains subfolders for different fruits and vegetables wherein the images for respective food items are present# Context\n",
    "\n",
    "This dataset contains images of the following food items:\n",
    "\n",
    "- **fruits**: banana, apple, pear, grapes, orange, kiwi, watermelon, pomegranate, pineapple, mango\n",
    "- **vegetables**: cucumber, carrot, capsicum, onion, potato, lemon, tomato, raddish, beetroot, cabbage, lettuce, spinach, soy bean, cauliflower, bell pepper, chilli pepper, turnip, corn, sweetcorn, sweet potato, paprika, jalepeño, ginger, garlic, peas, eggplant\n",
    "\n",
    "# Content\n",
    "This dataset contains three folders:\n",
    "\n",
    "- train (100 images each)\n",
    "- test (10 images each)\n",
    "- validation (10 images each)\n",
    "each of the above folders contains subfolders for different fruits and vegetables wherein the images for respective food items are present\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XFhtaM-2BoLo"
   },
   "source": [
    "# 1. Loading and preprocessing<a class=\"anchor\" id=\"1\"></a><a class=\"anchor\" id=\"1\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4QaxRl6eBoLo",
    "outputId": "569e204f-c2f1-4eb7-a30b-34872f27dbdc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Load the Drive helper and mount\n",
    "from google.colab import drive\n",
    "\n",
    "# This will prompt for authorization.\n",
    "mountdir = '/content/drive'\n",
    "drive.mount(mountdir, force_remount=True)\n",
    "\n",
    "localdir = mountdir + '/MyDrive'\n",
    "# Replace your folder here\n",
    "w281_directory = '/Berkeley/w281/Fruit-and-Vegetable-Classification/'\n",
    "inputdir = localdir + w281_directory\n",
    "# Uncomment below if using local folder\n",
    "#inputdir = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-30T08:40:40.436565Z",
     "iopub.status.busy": "2021-05-30T08:40:40.436021Z",
     "iopub.status.idle": "2021-05-30T08:40:42.259382Z",
     "shell.execute_reply": "2021-05-30T08:40:42.258422Z",
     "shell.execute_reply.started": "2021-05-30T08:40:40.436446Z"
    },
    "id": "b6tCm8LNBoLq"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import os.path\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "\n",
    "# Create a list with the filepaths for training and testing\n",
    "train_dir = Path(inputdir, './input/train')\n",
    "train_filepaths = list(train_dir.glob(r'**/*.jpg'))\n",
    "\n",
    "test_dir = Path(inputdir, './input/test')\n",
    "test_filepaths = list(test_dir.glob(r'**/*.jpg'))\n",
    "\n",
    "val_dir = Path(inputdir, './input/validation')\n",
    "val_filepaths = list(test_dir.glob(r'**/*.jpg'))\n",
    "\n",
    "def proc_img(filepath):\n",
    "    \"\"\" Create a DataFrame with the filepath and the labels of the pictures\n",
    "    \"\"\"\n",
    "\n",
    "    labels = [str(filepath[i]).split(\"/\")[-2] \\\n",
    "              for i in range(len(filepath))]\n",
    "\n",
    "    filepath = pd.Series(filepath, name='Filepath').astype(str)\n",
    "    labels = pd.Series(labels, name='Label')\n",
    "\n",
    "    # Concatenate filepaths and labels\n",
    "    df = pd.concat([filepath, labels], axis=1)\n",
    "\n",
    "    # Shuffle the DataFrame and reset index\n",
    "    df = df.sample(frac=1).reset_index(drop = True)\n",
    "\n",
    "    return df\n",
    "\n",
    "train_df = proc_img(train_filepaths)\n",
    "test_df = proc_img(test_filepaths)\n",
    "val_df = proc_img(val_filepaths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2021-05-30T08:40:42.261208Z",
     "iopub.status.busy": "2021-05-30T08:40:42.260878Z",
     "iopub.status.idle": "2021-05-30T08:40:42.269274Z",
     "shell.execute_reply": "2021-05-30T08:40:42.268398Z",
     "shell.execute_reply.started": "2021-05-30T08:40:42.261172Z"
    },
    "id": "U30yJSAHBoLr",
    "outputId": "c01c6623-2d6f-4d2c-aeac-32bd09917ce8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Training set --\n",
      "\n",
      "Number of pictures: 110\n",
      "\n",
      "Number of different labels: 2\n",
      "\n",
      "Labels: ['apple' 'turnip']\n"
     ]
    }
   ],
   "source": [
    "print('-- Training set --\\n')\n",
    "print(f'Number of pictures: {train_df.shape[0]}\\n')\n",
    "print(f'Number of different labels: {len(train_df.Label.unique())}\\n')\n",
    "print(f'Labels: {train_df.Label.unique()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-30T08:40:42.271618Z",
     "iopub.status.busy": "2021-05-30T08:40:42.271099Z",
     "iopub.status.idle": "2021-05-30T08:40:42.291191Z",
     "shell.execute_reply": "2021-05-30T08:40:42.290395Z",
     "shell.execute_reply.started": "2021-05-30T08:40:42.271581Z"
    },
    "id": "dn6YDXkPBoLr"
   },
   "outputs": [],
   "source": [
    "# The DataFrame with the filepaths in one column and the labels in the other one\n",
    "train_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-30T08:40:42.293366Z",
     "iopub.status.busy": "2021-05-30T08:40:42.292982Z",
     "iopub.status.idle": "2021-05-30T08:40:48.718339Z",
     "shell.execute_reply": "2021-05-30T08:40:48.717443Z",
     "shell.execute_reply.started": "2021-05-30T08:40:42.293327Z"
    },
    "id": "0VjaZ0usBoLr"
   },
   "outputs": [],
   "source": [
    "# Create a DataFrame with one Label of each category\n",
    "df_unique = train_df.copy().drop_duplicates(subset=[\"Label\"]).reset_index()\n",
    "\n",
    "# Display some pictures of the dataset\n",
    "fig, axes = plt.subplots(nrows=6, ncols=6, figsize=(8, 7),\n",
    "                        subplot_kw={'xticks': [], 'yticks': []})\n",
    "\n",
    "for i, ax in enumerate(axes.flat):\n",
    "    ax.imshow(plt.imread(df_unique.Filepath[i]))\n",
    "    ax.set_title(df_unique.Label[i], fontsize = 12)\n",
    "plt.tight_layout(pad=0.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-Q4kjYPzBoLs"
   },
   "source": [
    "# 2. Load the Images with a generator and Data Augmentation<a class=\"anchor\" id=\"2\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-30T08:40:48.719985Z",
     "iopub.status.busy": "2021-05-30T08:40:48.719601Z",
     "iopub.status.idle": "2021-05-30T08:40:50.072288Z",
     "shell.execute_reply": "2021-05-30T08:40:50.071197Z",
     "shell.execute_reply.started": "2021-05-30T08:40:48.719949Z"
    },
    "id": "YUIcb7JUBoLs"
   },
   "outputs": [],
   "source": [
    "train_generator = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "    preprocessing_function=tf.keras.applications.mobilenet_v2.preprocess_input\n",
    ")\n",
    "\n",
    "test_generator = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "    preprocessing_function=tf.keras.applications.mobilenet_v2.preprocess_input\n",
    ")\n",
    "\n",
    "train_images = train_generator.flow_from_dataframe(\n",
    "    dataframe=train_df,\n",
    "    x_col='Filepath',\n",
    "    y_col='Label',\n",
    "    target_size=(224, 224),\n",
    "    color_mode='rgb',\n",
    "    class_mode='categorical',\n",
    "    batch_size=32,\n",
    "    shuffle=True,\n",
    "    seed=0,\n",
    "    rotation_range=30,\n",
    "    zoom_range=0.15,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.15,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode=\"nearest\"\n",
    ")\n",
    "\n",
    "val_images = train_generator.flow_from_dataframe(\n",
    "    dataframe=val_df,\n",
    "    x_col='Filepath',\n",
    "    y_col='Label',\n",
    "    target_size=(224, 224),\n",
    "    color_mode='rgb',\n",
    "    class_mode='categorical',\n",
    "    batch_size=32,\n",
    "    shuffle=True,\n",
    "    seed=0,\n",
    "    rotation_range=30,\n",
    "    zoom_range=0.15,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.15,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode=\"nearest\"\n",
    ")\n",
    "\n",
    "test_images = test_generator.flow_from_dataframe(\n",
    "    dataframe=test_df,\n",
    "    x_col='Filepath',\n",
    "    y_col='Label',\n",
    "    target_size=(224, 224),\n",
    "    color_mode='rgb',\n",
    "    class_mode='categorical',\n",
    "    batch_size=32,\n",
    "    shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-output": true,
    "execution": {
     "iopub.execute_input": "2021-05-30T08:40:50.075611Z",
     "iopub.status.busy": "2021-05-30T08:40:50.075326Z",
     "iopub.status.idle": "2021-05-30T08:40:52.071504Z",
     "shell.execute_reply": "2021-05-30T08:40:52.070569Z",
     "shell.execute_reply.started": "2021-05-30T08:40:50.075582Z"
    },
    "id": "9Bq2x9rGBoLt"
   },
   "outputs": [],
   "source": [
    "# Load the pretained model\n",
    "pretrained_model = tf.keras.applications.MobileNetV2(\n",
    "    input_shape=(224, 224, 3),\n",
    "    include_top=False,\n",
    "    weights='imagenet',\n",
    "    pooling='avg'\n",
    ")\n",
    "pretrained_model.trainable = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JZHPBWN2BoLu"
   },
   "source": [
    "# 3. Train the model<a class=\"anchor\" id=\"3\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-output": true,
    "execution": {
     "iopub.execute_input": "2021-05-30T08:40:52.07325Z",
     "iopub.status.busy": "2021-05-30T08:40:52.072882Z",
     "iopub.status.idle": "2021-05-30T08:51:35.585279Z",
     "shell.execute_reply": "2021-05-30T08:51:35.58375Z",
     "shell.execute_reply.started": "2021-05-30T08:40:52.073197Z"
    },
    "id": "hpaVyW5MBoLu"
   },
   "outputs": [],
   "source": [
    "inputs = pretrained_model.input\n",
    "\n",
    "x = tf.keras.layers.Dense(128, activation='relu')(pretrained_model.output)\n",
    "x = tf.keras.layers.Dense(128, activation='relu')(x)\n",
    "\n",
    "outputs = tf.keras.layers.Dense(36, activation='softmax')(x)\n",
    "\n",
    "model = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "history = model.fit(\n",
    "    train_images,\n",
    "    validation_data=val_images,\n",
    "    batch_size = 32,\n",
    "    epochs=5,\n",
    "    callbacks=[\n",
    "        tf.keras.callbacks.EarlyStopping(\n",
    "            monitor='val_loss',\n",
    "            patience=2,\n",
    "            restore_best_weights=True\n",
    "        )\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-30T08:51:35.593715Z",
     "iopub.status.busy": "2021-05-30T08:51:35.5933Z",
     "iopub.status.idle": "2021-05-30T08:51:35.795823Z",
     "shell.execute_reply": "2021-05-30T08:51:35.795014Z",
     "shell.execute_reply.started": "2021-05-30T08:51:35.593665Z"
    },
    "id": "Kz2x9Z6jBoLv"
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(history.history)[['accuracy','val_accuracy']].plot()\n",
    "plt.title(\"Accuracy\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-30T08:51:35.797874Z",
     "iopub.status.busy": "2021-05-30T08:51:35.797473Z",
     "iopub.status.idle": "2021-05-30T08:51:35.969543Z",
     "shell.execute_reply": "2021-05-30T08:51:35.968488Z",
     "shell.execute_reply.started": "2021-05-30T08:51:35.797833Z"
    },
    "id": "rYwT7ZNYBoLv"
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(history.history)[['loss','val_loss']].plot()\n",
    "plt.title(\"Loss\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2OJ2rxLqBoLv"
   },
   "source": [
    "# 4. Visualize the result<a class=\"anchor\" id=\"4\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-output": true,
    "execution": {
     "iopub.execute_input": "2021-05-30T08:51:35.971442Z",
     "iopub.status.busy": "2021-05-30T08:51:35.971059Z",
     "iopub.status.idle": "2021-05-30T08:51:53.343485Z",
     "shell.execute_reply": "2021-05-30T08:51:53.342485Z",
     "shell.execute_reply.started": "2021-05-30T08:51:35.971403Z"
    },
    "id": "yE5l5-DbBoLv"
   },
   "outputs": [],
   "source": [
    "# Predict the label of the test_images\n",
    "pred = model.predict(test_images)\n",
    "pred = np.argmax(pred,axis=1)\n",
    "\n",
    "# Map the label\n",
    "labels = (train_images.class_indices)\n",
    "labels = dict((v,k) for k,v in labels.items())\n",
    "pred = [labels[k] for k in pred]\n",
    "\n",
    "y_test = [labels[k] for k in test_images.classes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-30T08:54:38.504565Z",
     "iopub.status.busy": "2021-05-30T08:54:38.504182Z",
     "iopub.status.idle": "2021-05-30T08:54:38.514042Z",
     "shell.execute_reply": "2021-05-30T08:54:38.510923Z",
     "shell.execute_reply.started": "2021-05-30T08:54:38.504532Z"
    },
    "id": "8za8FCE7BoLw"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "acc = accuracy_score(y_test, pred)\n",
    "print(f'Accuracy on the test set: {100*acc:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-30T08:51:53.345398Z",
     "iopub.status.busy": "2021-05-30T08:51:53.345004Z",
     "iopub.status.idle": "2021-05-30T08:51:57.833613Z",
     "shell.execute_reply": "2021-05-30T08:51:57.832791Z",
     "shell.execute_reply.started": "2021-05-30T08:51:53.345345Z"
    },
    "id": "qI89T9CyBoLw"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "\n",
    "cf_matrix = confusion_matrix(y_test, pred, normalize='true')\n",
    "plt.figure(figsize = (15,10))\n",
    "sns.heatmap(cf_matrix,\n",
    "            annot=True,\n",
    "            xticklabels = sorted(set(y_test)),\n",
    "            yticklabels = sorted(set(y_test)),\n",
    "            )\n",
    "plt.title('Normalized Confusion Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-30T08:51:57.835179Z",
     "iopub.status.busy": "2021-05-30T08:51:57.834852Z",
     "iopub.status.idle": "2021-05-30T08:51:59.808507Z",
     "shell.execute_reply": "2021-05-30T08:51:59.807411Z",
     "shell.execute_reply.started": "2021-05-30T08:51:57.835151Z"
    },
    "id": "TuUajuxpBoLw"
   },
   "outputs": [],
   "source": [
    "# Display some pictures of the dataset with their labels and the predictions\n",
    "fig, axes = plt.subplots(nrows=3, ncols=3, figsize=(15, 15),\n",
    "                        subplot_kw={'xticks': [], 'yticks': []})\n",
    "\n",
    "for i, ax in enumerate(axes.flat):\n",
    "    ax.imshow(plt.imread(test_df.Filepath.iloc[i]))\n",
    "    ax.set_title(f\"True: {test_df.Label.iloc[i]}\\nPredicted: {pred[i]}\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cgF4yYQVBoLx"
   },
   "source": [
    "## 5. Class activation heatmap for image classification<a class=\"anchor\" id=\"5\"></a>\n",
    "### Grad-CAM class activation visualization\n",
    "*Code adapted from keras.io*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-30T08:51:59.810749Z",
     "iopub.status.busy": "2021-05-30T08:51:59.810028Z",
     "iopub.status.idle": "2021-05-30T08:51:59.829867Z",
     "shell.execute_reply": "2021-05-30T08:51:59.828894Z",
     "shell.execute_reply.started": "2021-05-30T08:51:59.810696Z"
    },
    "id": "POQMg6vxBoLx"
   },
   "outputs": [],
   "source": [
    "import matplotlib.cm as cm\n",
    "\n",
    "def get_img_array(img_path, size):\n",
    "    img = tf.keras.preprocessing.image.load_img(img_path, target_size=size)\n",
    "    array = tf.keras.preprocessing.image.img_to_array(img)\n",
    "    # We add a dimension to transform our array into a \"batch\"\n",
    "    # of size \"size\"\n",
    "    array = np.expand_dims(array, axis=0)\n",
    "    return array\n",
    "\n",
    "def make_gradcam_heatmap(img_array, model, last_conv_layer_name, pred_index=None):\n",
    "    # First, we create a model that maps the input image to the activations\n",
    "    # of the last conv layer as well as the output predictions\n",
    "    grad_model = tf.keras.models.Model(\n",
    "        [model.inputs], [model.get_layer(last_conv_layer_name).output, model.output]\n",
    "    )\n",
    "\n",
    "    # Then, we compute the gradient of the top predicted class for our input image\n",
    "    # with respect to the activations of the last conv layer\n",
    "    with tf.GradientTape() as tape:\n",
    "        last_conv_layer_output, preds = grad_model(img_array)\n",
    "        if pred_index is None:\n",
    "            pred_index = tf.argmax(preds[0])\n",
    "        class_channel = preds[:, pred_index]\n",
    "\n",
    "    # This is the gradient of the output neuron (top predicted or chosen)\n",
    "    # with regard to the output feature map of the last conv layer\n",
    "    grads = tape.gradient(class_channel, last_conv_layer_output)\n",
    "\n",
    "    # This is a vector where each entry is the mean intensity of the gradient\n",
    "    # over a specific feature map channel\n",
    "    pooled_grads = tf.reduce_mean(grads, axis=(0, 1, 2))\n",
    "\n",
    "    # We multiply each channel in the feature map array\n",
    "    # by \"how important this channel is\" with regard to the top predicted class\n",
    "    # then sum all the channels to obtain the heatmap class activation\n",
    "    last_conv_layer_output = last_conv_layer_output[0]\n",
    "    heatmap = last_conv_layer_output @ pooled_grads[..., tf.newaxis]\n",
    "    heatmap = tf.squeeze(heatmap)\n",
    "\n",
    "    # For visualization purpose, we will also normalize the heatmap between 0 & 1\n",
    "    heatmap = tf.maximum(heatmap, 0) / tf.math.reduce_max(heatmap)\n",
    "    return heatmap.numpy()\n",
    "\n",
    "def save_and_display_gradcam(img_path, heatmap, cam_path=\"cam.jpg\", alpha=0.4):\n",
    "    # Load the original image\n",
    "    img = tf.keras.preprocessing.image.load_img(img_path)\n",
    "    img = tf.keras.preprocessing.image.img_to_array(img)\n",
    "\n",
    "    # Rescale heatmap to a range 0-255\n",
    "    heatmap = np.uint8(255 * heatmap)\n",
    "\n",
    "    # Use jet colormap to colorize heatmap\n",
    "    jet = cm.get_cmap(\"jet\")\n",
    "\n",
    "    # Use RGB values of the colormap\n",
    "    jet_colors = jet(np.arange(256))[:, :3]\n",
    "    jet_heatmap = jet_colors[heatmap]\n",
    "\n",
    "    # Create an image with RGB colorized heatmap\n",
    "    jet_heatmap = tf.keras.preprocessing.image.array_to_img(jet_heatmap)\n",
    "    jet_heatmap = jet_heatmap.resize((img.shape[1], img.shape[0]))\n",
    "    jet_heatmap = tf.keras.preprocessing.image.img_to_array(jet_heatmap)\n",
    "\n",
    "    # Superimpose the heatmap on original image\n",
    "    superimposed_img = jet_heatmap * alpha + img\n",
    "    superimposed_img = tf.keras.preprocessing.image.array_to_img(superimposed_img)\n",
    "\n",
    "    # Save the superimposed image\n",
    "    superimposed_img.save(cam_path)\n",
    "\n",
    "    # Display Grad CAM\n",
    "#     display(Image(cam_path))\n",
    "\n",
    "    return cam_path\n",
    "\n",
    "preprocess_input = tf.keras.applications.mobilenet_v2.preprocess_input\n",
    "decode_predictions = tf.keras.applications.mobilenet_v2.decode_predictions\n",
    "\n",
    "last_conv_layer_name = \"Conv_1\"\n",
    "img_size = (224,224)\n",
    "\n",
    "# Remove last layer's softmax\n",
    "model.layers[-1].ativation = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-30T08:51:59.832075Z",
     "iopub.status.busy": "2021-05-30T08:51:59.83139Z",
     "iopub.status.idle": "2021-05-30T08:52:04.070361Z",
     "shell.execute_reply": "2021-05-30T08:52:04.069257Z",
     "shell.execute_reply.started": "2021-05-30T08:51:59.832037Z"
    },
    "id": "dslxNm4rBoLx"
   },
   "outputs": [],
   "source": [
    "# Display the part of the pictures used by the neural network to classify the pictures\n",
    "fig, axes = plt.subplots(nrows=3, ncols=3, figsize=(15, 15),\n",
    "                        subplot_kw={'xticks': [], 'yticks': []})\n",
    "\n",
    "for i, ax in enumerate(axes.flat):\n",
    "    img_path = test_df.Filepath.iloc[i]\n",
    "    img_array = preprocess_input(get_img_array(img_path, size=img_size))\n",
    "    heatmap = make_gradcam_heatmap(img_array, model, last_conv_layer_name)\n",
    "    cam_path = save_and_display_gradcam(img_path, heatmap)\n",
    "    ax.imshow(plt.imread(cam_path))\n",
    "    ax.set_title(f\"True: {test_df.Label.iloc[i]}\\nPredicted: {pred[i]}\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
