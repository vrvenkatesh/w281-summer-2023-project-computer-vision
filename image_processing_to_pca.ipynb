{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MichaelTay/w281-summer-2023-project/blob/main/image_processing_to_pca.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1p8wbonrBoLl"
      },
      "source": [
        "# Fruit and Vegetable Image Processing\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-07-25T15:48:10.352967Z",
          "start_time": "2023-07-25T15:48:10.352812Z"
        },
        "id": "3qSIiM8kKE8d",
        "tags": []
      },
      "outputs": [],
      "source": [
        "#importing required libraries\n",
        "from skimage.io import imread\n",
        "from skimage.transform import resize\n",
        "from skimage.feature import hog, daisy\n",
        "from skimage.color import rgb2gray\n",
        "from skimage import exposure\n",
        "import matplotlib.pyplot as plt\n",
        "import pickle\n",
        "import gc\n",
        "\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "# Load the Drive helper and mount\n",
        "#from google.colab import drive\n",
        "import xarray as x\n",
        "import sys"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XFhtaM-2BoLo"
      },
      "source": [
        "# 1. Loading and preprocessing<a class=\"anchor\" id=\"1\"></a><a class=\"anchor\" id=\"1\"></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-07-25T15:48:10.605525Z",
          "start_time": "2023-07-25T15:48:10.605339Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b6tCm8LNBoLq",
        "outputId": "e2b7b8c6-0439-4988-9f08-9a7c340da282",
        "tags": []
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "# Load the Drive helper and mount\n",
        "from google.colab import drive\n",
        "\n",
        "# This will prompt for authorization.\n",
        "mountdir = '/content/drive'\n",
        "drive.mount(mountdir, force_remount=True)\n",
        "\n",
        "localdir = mountdir + '/MyDrive'\n",
        "# Replace your folder here\n",
        "w281_directory = '/Berkeley/w281/Fruit-and-Vegetable-Classification/'\n",
        "inputdir = localdir + w281_directory\n",
        "# Uncomment below if using local folder\n",
        "# inputdir = \"/Users/mcliston/Library/CloudStorage/GoogleDrive-michael.c.liston@gmail.com/My Drive/Berkeley/w281/Fruit-and-Vegetable-Classification/\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-07-25T15:48:10.637197Z",
          "start_time": "2023-07-25T15:48:10.637044Z"
        },
        "id": "CX0NY9FsI5tm",
        "tags": []
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "import os.path\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "#import tensorflow as tf\n",
        "\n",
        "# Create a list with the filepaths for training and testing\n",
        "train_dir = Path(inputdir, './input/train')\n",
        "train_filepaths = list(train_dir.glob(r'**/*.jpg'))\n",
        "\n",
        "test_dir = Path(inputdir, './input/test')\n",
        "test_filepaths = list(test_dir.glob(r'**/*.jpg'))\n",
        "\n",
        "val_dir = Path(inputdir, './input/validation')\n",
        "val_filepaths = list(test_dir.glob(r'**/*.jpg'))\n",
        "\n",
        "def proc_img(filepath):\n",
        "    \"\"\" Create a DataFrame with the filepath and the labels of the pictures\n",
        "    \"\"\"\n",
        "\n",
        "    labels = [str(filepath[i]).split(\"/\")[-2] \\\n",
        "              for i in range(len(filepath))]\n",
        "\n",
        "    filepath = pd.Series(filepath, name='Filepath').astype(str)\n",
        "    labels = pd.Series(labels, name='Label')\n",
        "\n",
        "    # Concatenate filepaths and labels\n",
        "    df = pd.concat([filepath, labels], axis=1)\n",
        "\n",
        "    # Shuffle the DataFrame and reset index\n",
        "    df = df.sample(frac=1).reset_index(drop = True)\n",
        "\n",
        "    return df\n",
        "\n",
        "train_df = proc_img(train_filepaths)\n",
        "test_df = proc_img(test_filepaths)\n",
        "val_df = proc_img(val_filepaths)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ud7SHtuMJvjI"
      },
      "source": [
        "# Filter only selected class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-07-25T15:48:10.637415Z",
          "start_time": "2023-07-25T15:48:10.637361Z"
        },
        "id": "jESFwwfjJvjI",
        "tags": []
      },
      "outputs": [],
      "source": [
        "# Fruits - banana, apple, pear, grapes, orange, kiwi, watermelon, pomegranate, pineapple, mango.\n",
        "# Vegetables - Bell Pepper, Cauliflower, Chilli Pepper, Peas, Corn, Spinach, Turnip, Garlic, Ginger, Cabbage\n",
        "Fruits = ['banana', 'apple', 'pear', 'grapes', 'orange', 'kiwi', 'watermelon', 'pomegranate', 'pineapple', 'mango']\n",
        "Vegetables = ['bell pepper', 'cauliflower', 'chilli pepper', 'peas', 'corn', 'spinach', 'turnip', 'garlic', 'ginger', 'cabbage']\n",
        "\n",
        "train_df = train_df[train_df['Label'].isin(Fruits + Vegetables)]\n",
        "test_df = test_df[test_df['Label'].isin(Fruits + Vegetables)]\n",
        "val_df = val_df[val_df['Label'].isin(Fruits + Vegetables)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-07-25T15:48:10.641028Z",
          "start_time": "2023-07-25T15:48:10.640928Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U30yJSAHBoLr",
        "outputId": "21d4a70e-344f-42a5-8a71-4095e2837ec4",
        "tags": []
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-- Training set --\n",
            "\n",
            "Number of pictures: 1540\n",
            "\n",
            "Number of different labels: 20\n",
            "\n",
            "Labels: ['pomegranate' 'watermelon' 'mango' 'chilli pepper' 'bell pepper' 'pear'\n",
            " 'garlic' 'cabbage' 'apple' 'grapes' 'kiwi' 'pineapple' 'turnip' 'spinach'\n",
            " 'banana' 'cauliflower' 'ginger' 'orange' 'corn' 'peas']\n"
          ]
        }
      ],
      "source": [
        "print('-- Training set --\\n')\n",
        "print(f'Number of pictures: {train_df.shape[0]}\\n')\n",
        "print(f'Number of different labels: {len(train_df.Label.unique())}\\n')\n",
        "print(f'Labels: {train_df.Label.unique()}')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Feature Extraction"
      ],
      "metadata": {
        "id": "UH7lKmLxUElw"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VZ6NcQrDM9pW"
      },
      "source": [
        "### Color and Edge Detection functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-07-25T15:48:10.714953Z",
          "start_time": "2023-07-25T15:48:10.714827Z"
        },
        "tags": [],
        "id": "ks9w3v14M9pW"
      },
      "outputs": [],
      "source": [
        "RANDOM_SEED = 1234\n",
        "IMG_DIM = 512\n",
        "PCA_DIM = 64\n",
        "\n",
        "def find_edges(img):\n",
        "\n",
        "  # converting to gray scale\n",
        "  gray = cv2.cvtColor(np.float32(img), cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "  # remove noise\n",
        "  img = cv2.GaussianBlur(gray,(3,3),0)\n",
        "\n",
        "  # convolve with proper kernels\n",
        "  laplacian = cv2.Laplacian(img,cv2.CV_32F)\n",
        "  sobelx = cv2.Sobel(img,cv2.CV_32F,1,0,ksize=5)  # x\n",
        "  sobely = cv2.Sobel(img,cv2.CV_32F,0,1,ksize=5)  # y\n",
        "\n",
        "  return laplacian, sobelx, sobely\n",
        "\n",
        "def get_color_features(im):\n",
        "\n",
        "  img_512 = resize(im, (512, 512), anti_aliasing=True).astype(np.float32)\n",
        "  hsv_image = cv2.cvtColor(img_512, cv2.COLOR_RGB2HSV)\n",
        "\n",
        "  hue_channel = hsv_image[:, :, 0]\n",
        "  saturation_channel = hsv_image[:, :, 1]\n",
        "  value_channel = hsv_image[:, :, 2]\n",
        "\n",
        "  return hue_channel, saturation_channel, value_channel\n",
        "\n",
        "\n",
        "def image_processing(path):\n",
        "\n",
        "    img = imread(path)\n",
        "\n",
        "    resized_img = resize(img, (IMG_DIM,IMG_DIM), anti_aliasing=True)\n",
        "\n",
        "    #creating hog features\n",
        "\n",
        "    fd, hog_image = hog(resized_img, orientations=8, pixels_per_cell=(8,8),\n",
        "                        cells_per_block=(4,4), visualize=True, channel_axis=-1)\n",
        "\n",
        "\n",
        "    # creating edge features\n",
        "    laplacian, sobelx, sobely = find_edges(resized_img)\n",
        "\n",
        "    # creating color features\n",
        "    hue_channel, saturation_channel, luminance_channel = get_color_features(resized_img)\n",
        "\n",
        "    gray_img = rgb2gray(resized_img)\n",
        "    descs = daisy(gray_img, step=150, radius=40, rings=2, histograms=6, orientations=8, visualize=False)\n",
        "\n",
        "    feature_lst = [hog_image, hue_channel, saturation_channel, luminance_channel, laplacian, sobelx, sobely, descs]\n",
        "\n",
        "    resized_features = [resize(z, (PCA_DIM, PCA_DIM), anti_aliasing=True) for z in feature_lst]\n",
        "\n",
        "    return resized_features\n",
        "\n",
        "def process_img(df):\n",
        "\n",
        "  hog_lst, hue_lst, sat_lst, lum_lst, lap_lst, sob_x_lst, sob_y_lst, daisy_lst = [],[],[],[],[],[],[],[]\n",
        "  final_labels = []\n",
        "\n",
        "  for i,j in enumerate(df.iterrows()):\n",
        "    print(f\"Processing image #: {i}\")\n",
        "    filepath,label = j[1]['Filepath'], j[1]['Label']\n",
        "\n",
        "    try:\n",
        "\n",
        "      features  = image_processing(filepath)\n",
        "      final_labels.append(label)\n",
        "\n",
        "    except Exception as e:\n",
        "\n",
        "      print(f\"There was an {e.__class__.__name__} error while trying to process an image... continuing\")\n",
        "      print(f\"The error occurred at image #{i}, {filepath}\")\n",
        "      continue\n",
        "\n",
        "    for k,l in enumerate([hog_lst,hue_lst,sat_lst,lum_lst,lap_lst,sob_x_lst,sob_y_lst,daisy_lst]):\n",
        "      feature = features[k].reshape(-1).astype(float)\n",
        "      feature = feature - np.mean(feature)\n",
        "      l.append(feature)\n",
        "\n",
        "\n",
        "  hog_arr = np.vstack(hog_lst)\n",
        "  hue_arr = np.vstack(hue_lst)\n",
        "  sat_arr = np.vstack(sat_lst)\n",
        "  lum_arr = np.vstack(lum_lst)\n",
        "  lap_arr = np.vstack(lap_lst)\n",
        "  sob_x_arr = np.vstack(sob_x_lst)\n",
        "  sob_y_arr = np.vstack(sob_y_lst)\n",
        "  daisy_arr = np.vstack(daisy_lst)\n",
        "\n",
        "  return [hog_arr, hue_arr, sat_arr, lum_arr, lap_arr, sob_x_arr, sob_y_arr, daisy_arr, final_labels]\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "RANDOM_SEED = 1234\n",
        "\n",
        "# train_set = train_df.sample(frac=0.9, random_state=RANDOM_SEED)\n",
        "# val_set = train_df[~(train_df.index.isin(train_set.index))]\n",
        "# test_set = val_df\n",
        "\n",
        "train_set = train_df\n",
        "val_set = val_df\n",
        "test_set = test_df"
      ],
      "metadata": {
        "id": "SUYVz8e0mZND"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Making Training set"
      ],
      "metadata": {
        "id": "9_7mRavvVAxG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_arrays = process_img(train_set)"
      ],
      "metadata": {
        "id": "iXLqRk_ncUTz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#primary features: Daisy, Luminance, Saturation, Hue, Maybe (HOG)\n",
        "\n",
        "# get training data\n",
        "full_dataset = np.concatenate((train_arrays[7],\n",
        "                               train_arrays[3],\n",
        "                               train_arrays[2],\n",
        "                               train_arrays[1]), axis=1)\n"
      ],
      "metadata": {
        "id": "KgEvTXRs1h_q"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## scale training set\n",
        "scaler = StandardScaler()\n",
        "scaled_full_dataset = scaler.fit_transform(full_dataset)\n",
        "\n",
        "# save scaler\n",
        "pickle_dir = ''\n",
        "pickle.dump(scaler, open(pickle_dir+'standardscaler.pkl', 'wb'))"
      ],
      "metadata": {
        "id": "PjQRUNEOsBXi"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# pca training set\n",
        "RANDOM_SEED = 1234\n",
        "pca = PCA(n_components=50, random_state=RANDOM_SEED)\n",
        "X = pca.fit_transform(scaled_full_dataset)\n",
        "\n",
        "## save pca object\n",
        "pickle_dir = ''\n",
        "pickle.dump(pca, open(pickle_dir+'pca.pkl', 'wb'))"
      ],
      "metadata": {
        "id": "w5BnGRziTTdU"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## combine training data with labels\n",
        "X = np.concatenate((X,np.array((train_arrays[-1])).reshape(-1,1)), axis=1)\n",
        "X_df = pd.DataFrame(X)\n",
        "\n",
        "# Daisy, Luminance, Saturation, Hue\n",
        "pca_dataset_dir = ''\n",
        "X_df.to_csv(pca_dataset_dir+'training_daisy_lum_sat_hue.csv')"
      ],
      "metadata": {
        "id": "mGLku4vAZbRU"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Making Validation set"
      ],
      "metadata": {
        "id": "S0q5riZuU4df"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "validation_arrays = process_img(val_set)"
      ],
      "metadata": {
        "id": "ukNE0Pmo19-4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#primary features: Daisy, Luminance, Saturation, Hue, Maybe (HOG)\n",
        "## get validation dataset\n",
        "full_validation_dataset = np.concatenate((validation_arrays[7],\n",
        "                               validation_arrays[3],\n",
        "                               validation_arrays[2],\n",
        "                               validation_arrays[1]), axis=1)"
      ],
      "metadata": {
        "id": "sgd1FJRQVJuW"
      },
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## scale, apply pca and export\n",
        "scaled_validation_dataset = scaler.transform(full_validation_dataset)\n",
        "X_val = pca.transform(scaled_validation_dataset)\n",
        "X_val = np.concatenate((X_val,np.array((validation_arrays[-1])).reshape(-1,1)), axis=1)\n",
        "X_val_df = pd.DataFrame(X_val)\n",
        "X_val_df.to_csv(pca_dataset_dir+'validation_daisy_lum_sat_hue.csv')"
      ],
      "metadata": {
        "id": "N8aFKJeR1ixU"
      },
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Making Testing set"
      ],
      "metadata": {
        "id": "uI95O4Q1Xgsx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_arrays = process_img(test_set)"
      ],
      "metadata": {
        "id": "Be3a3DB5Xdw5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# hog_arr, hue_arr, sat_arr, lum_arr, lap_arr, sob_x_arr, sob_y_arr, final_labels\n",
        "\n",
        "## get test dataset\n",
        "full_test_dataset = np.concatenate((test_arrays[7],\n",
        "                               test_arrays[3],\n",
        "                               test_arrays[2],\n",
        "                               test_arrays[1]), axis=1)"
      ],
      "metadata": {
        "id": "NlrJVnAUXm2T"
      },
      "execution_count": 87,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## scale, apply pca and export\n",
        "scaled_test_dataset = scaler.transform(full_test_dataset)\n",
        "X_test = pca.transform(scaled_test_dataset)\n",
        "X_test = np.concatenate((X_test,np.array((test_arrays[-1])).reshape(-1,1)), axis=1)\n",
        "X_test_df = pd.DataFrame(X_test)\n",
        "X_test_df.to_csv(pca_dataset_dir+'test_daisy_lum_sat_hue.csv')"
      ],
      "metadata": {
        "id": "Lla_lrFC6xnZ"
      },
      "execution_count": 96,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(X_df.shape)\n",
        "print(X_val_df.shape)\n",
        "print(X_test_df.shape)"
      ],
      "metadata": {
        "id": "bX4GS3-n7gQF",
        "outputId": "45f9210c-973e-4f76-88f2-10f75935526e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1535, 51)\n",
            "(187, 51)\n",
            "(187, 51)\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}