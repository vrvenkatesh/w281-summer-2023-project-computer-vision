{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MichaelTay/w281-summer-2023-project/blob/main/image_processing_to_pca.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1p8wbonrBoLl"
      },
      "source": [
        "# Fruit and Vegetable Image Processing\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-07-25T15:48:10.352967Z",
          "start_time": "2023-07-25T15:48:10.352812Z"
        },
        "id": "3qSIiM8kKE8d",
        "tags": []
      },
      "outputs": [],
      "source": [
        "#importing required libraries\n",
        "from skimage.io import imread\n",
        "from skimage.transform import resize\n",
        "from skimage.feature import hog, daisy\n",
        "from skimage.color import rgb2gray\n",
        "from skimage import exposure\n",
        "import matplotlib.pyplot as plt\n",
        "import pickle\n",
        "import gc\n",
        "\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "# Load the Drive helper and mount\n",
        "#from google.colab import drive\n",
        "import xarray as x\n",
        "import sys"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XFhtaM-2BoLo"
      },
      "source": [
        "# 1. Loading and preprocessing<a class=\"anchor\" id=\"1\"></a><a class=\"anchor\" id=\"1\"></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-07-25T15:48:10.605525Z",
          "start_time": "2023-07-25T15:48:10.605339Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b6tCm8LNBoLq",
        "outputId": "ea603488-fc0c-428e-f833-dec5e2f13eae",
        "tags": []
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "# Load the Drive helper and mount\n",
        "from google.colab import drive\n",
        "\n",
        "# This will prompt for authorization.\n",
        "mountdir = '/content/drive'\n",
        "drive.mount(mountdir, force_remount=True)\n",
        "\n",
        "localdir = mountdir + '/MyDrive'\n",
        "# Replace your folder here\n",
        "w281_directory = '/Berkeley/w281/Fruit-and-Vegetable-Classification/'\n",
        "inputdir = localdir + w281_directory\n",
        "pca_dataset_dir = inputdir + 'modeling/pca_datasets/'\n",
        "pca_pickle_dir = inputdir + 'modeling/pca_pickle/'\n",
        "# Uncomment below if using local folder\n",
        "# inputdir = \"/Users/mcliston/Library/CloudStorage/GoogleDrive-michael.c.liston@gmail.com/My Drive/Berkeley/w281/Fruit-and-Vegetable-Classification/\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-07-25T15:48:10.637197Z",
          "start_time": "2023-07-25T15:48:10.637044Z"
        },
        "id": "CX0NY9FsI5tm",
        "tags": []
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "import os.path\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "#import tensorflow as tf\n",
        "\n",
        "# Create a list with the filepaths for training and testing\n",
        "train_dir = Path(inputdir, './input/train')\n",
        "train_filepaths = list(train_dir.glob(r'**/*.jpg'))\n",
        "\n",
        "test_dir = Path(inputdir, './input/test')\n",
        "test_filepaths = list(test_dir.glob(r'**/*.jpg'))\n",
        "\n",
        "val_dir = Path(inputdir, './input/validation')\n",
        "val_filepaths = list(test_dir.glob(r'**/*.jpg'))\n",
        "\n",
        "def proc_img(filepath):\n",
        "    \"\"\" Create a DataFrame with the filepath and the labels of the pictures\n",
        "    \"\"\"\n",
        "\n",
        "    labels = [str(filepath[i]).split(\"/\")[-2] \\\n",
        "              for i in range(len(filepath))]\n",
        "\n",
        "    filepath = pd.Series(filepath, name='Filepath').astype(str)\n",
        "    labels = pd.Series(labels, name='Label')\n",
        "\n",
        "    # Concatenate filepaths and labels\n",
        "    df = pd.concat([filepath, labels], axis=1)\n",
        "\n",
        "    # Shuffle the DataFrame and reset index\n",
        "    df = df.sample(frac=1).reset_index(drop = True)\n",
        "\n",
        "    return df\n",
        "\n",
        "train_df = proc_img(train_filepaths)\n",
        "test_df = proc_img(test_filepaths)\n",
        "val_df = proc_img(val_filepaths)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gc"
      ],
      "metadata": {
        "id": "FJCXXAXvNZsD"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ud7SHtuMJvjI"
      },
      "source": [
        "# Filter only selected class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-07-25T15:48:10.637415Z",
          "start_time": "2023-07-25T15:48:10.637361Z"
        },
        "id": "jESFwwfjJvjI",
        "tags": []
      },
      "outputs": [],
      "source": [
        "# Fruits - banana, apple, pear, grapes, orange, kiwi, watermelon, pomegranate, pineapple, mango.\n",
        "# Vegetables - Bell Pepper, Cauliflower, Chilli Pepper, Peas, Corn, Spinach, Turnip, Garlic, Ginger, Cabbage\n",
        "Fruits = ['banana', 'apple', 'pear', 'grapes', 'orange', 'kiwi', 'watermelon', 'pomegranate', 'pineapple', 'mango']\n",
        "Vegetables = ['bell pepper', 'cauliflower', 'chilli pepper', 'peas', 'corn', 'spinach', 'turnip', 'garlic', 'ginger', 'cabbage']\n",
        "\n",
        "train_df = train_df[train_df['Label'].isin(Fruits + Vegetables)]\n",
        "test_df = test_df[test_df['Label'].isin(Fruits + Vegetables)]\n",
        "val_df = val_df[val_df['Label'].isin(Fruits + Vegetables)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-07-25T15:48:10.641028Z",
          "start_time": "2023-07-25T15:48:10.640928Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U30yJSAHBoLr",
        "outputId": "719641bb-d757-4ef8-97f5-680007cf24d3",
        "tags": []
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-- Training set --\n",
            "\n",
            "Number of pictures: 1540\n",
            "\n",
            "Number of different labels: 20\n",
            "\n",
            "Labels: ['pear' 'peas' 'ginger' 'banana' 'corn' 'turnip' 'cabbage' 'pineapple'\n",
            " 'bell pepper' 'cauliflower' 'orange' 'grapes' 'mango' 'chilli pepper'\n",
            " 'garlic' 'spinach' 'pomegranate' 'watermelon' 'kiwi' 'apple']\n"
          ]
        }
      ],
      "source": [
        "print('-- Training set --\\n')\n",
        "print(f'Number of pictures: {train_df.shape[0]}\\n')\n",
        "print(f'Number of different labels: {len(train_df.Label.unique())}\\n')\n",
        "print(f'Labels: {train_df.Label.unique()}')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Feature Extraction"
      ],
      "metadata": {
        "id": "UH7lKmLxUElw"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VZ6NcQrDM9pW"
      },
      "source": [
        "### Color and Edge Detection functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-07-25T15:48:10.714953Z",
          "start_time": "2023-07-25T15:48:10.714827Z"
        },
        "tags": [],
        "id": "ks9w3v14M9pW"
      },
      "outputs": [],
      "source": [
        "RANDOM_SEED = 1234\n",
        "IMG_DIM = 512\n",
        "PCA_DIM = 64\n",
        "\n",
        "def find_edges(img):\n",
        "\n",
        "  # converting to gray scale\n",
        "  gray = cv2.cvtColor(np.float32(img), cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "  # remove noise\n",
        "  img = cv2.GaussianBlur(gray,(3,3),0)\n",
        "\n",
        "  # convolve with proper kernels\n",
        "  laplacian = cv2.Laplacian(img,cv2.CV_32F)\n",
        "  sobelx = cv2.Sobel(img,cv2.CV_32F,1,0,ksize=5)  # x\n",
        "  sobely = cv2.Sobel(img,cv2.CV_32F,0,1,ksize=5)  # y\n",
        "\n",
        "  return laplacian, sobelx, sobely\n",
        "\n",
        "def get_color_features(im):\n",
        "\n",
        "  img_512 = resize(im, (512, 512), anti_aliasing=True).astype(np.float32)\n",
        "  hsv_image = cv2.cvtColor(img_512, cv2.COLOR_RGB2HSV)\n",
        "\n",
        "  hue_channel = hsv_image[:, :, 0]\n",
        "  saturation_channel = hsv_image[:, :, 1]\n",
        "  value_channel = hsv_image[:, :, 2]\n",
        "\n",
        "  return hue_channel, saturation_channel, value_channel\n",
        "\n",
        "\n",
        "def image_processing(path):\n",
        "\n",
        "    img = imread(path)\n",
        "\n",
        "    resized_img = resize(img, (IMG_DIM,IMG_DIM), anti_aliasing=True)\n",
        "\n",
        "    #creating hog features\n",
        "\n",
        "    fd, hog_image = hog(resized_img, orientations=8, pixels_per_cell=(8,8),\n",
        "                        cells_per_block=(4,4), visualize=True, channel_axis=-1)\n",
        "\n",
        "\n",
        "    # creating edge features\n",
        "    laplacian, sobelx, sobely = find_edges(resized_img)\n",
        "\n",
        "    # creating color features\n",
        "    hue_channel, saturation_channel, luminance_channel = get_color_features(resized_img)\n",
        "\n",
        "    gray_img = rgb2gray(resized_img)\n",
        "    descs = daisy(gray_img, step=150, radius=40, rings=2, histograms=6, orientations=8, visualize=False)\n",
        "\n",
        "    feature_lst = [hog_image, hue_channel, saturation_channel, luminance_channel, laplacian, sobelx, sobely, descs]\n",
        "\n",
        "    resized_features = [resize(z, (PCA_DIM, PCA_DIM), anti_aliasing=True) for z in feature_lst]\n",
        "\n",
        "    return resized_features\n",
        "\n",
        "def process_img(df):\n",
        "\n",
        "  hog_lst, hue_lst, sat_lst, lum_lst, lap_lst, sob_x_lst, sob_y_lst, daisy_lst = [],[],[],[],[],[],[],[]\n",
        "  final_labels = []\n",
        "\n",
        "  for i,j in enumerate(df.iterrows()):\n",
        "    print(f\"Processing image #: {i}\")\n",
        "    filepath,label = j[1]['Filepath'], j[1]['Label']\n",
        "\n",
        "    try:\n",
        "\n",
        "      features  = image_processing(filepath)\n",
        "      final_labels.append(label)\n",
        "\n",
        "    except Exception as e:\n",
        "\n",
        "      print(f\"There was an {e.__class__.__name__} error while trying to process an image... continuing\")\n",
        "      print(f\"The error occurred at image #{i}, {filepath}\")\n",
        "      continue\n",
        "\n",
        "    for k,l in enumerate([hog_lst,hue_lst,sat_lst,lum_lst,lap_lst,sob_x_lst,sob_y_lst,daisy_lst]):\n",
        "      feature = features[k].reshape(-1).astype(float)\n",
        "      feature = feature - np.mean(feature)\n",
        "      l.append(feature)\n",
        "\n",
        "\n",
        "  hog_arr = np.vstack(hog_lst)\n",
        "  hue_arr = np.vstack(hue_lst)\n",
        "  sat_arr = np.vstack(sat_lst)\n",
        "  lum_arr = np.vstack(lum_lst)\n",
        "  lap_arr = np.vstack(lap_lst)\n",
        "  sob_x_arr = np.vstack(sob_x_lst)\n",
        "  sob_y_arr = np.vstack(sob_y_lst)\n",
        "  daisy_arr = np.vstack(daisy_lst)\n",
        "\n",
        "  return [hog_arr, hue_arr, sat_arr, lum_arr, lap_arr, sob_x_arr, sob_y_arr, daisy_arr, final_labels]\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "RANDOM_SEED = 1234\n",
        "\n",
        "# train_set = train_df.sample(frac=0.9, random_state=RANDOM_SEED)\n",
        "# val_set = train_df[~(train_df.index.isin(train_set.index))]\n",
        "# test_set = val_df\n",
        "\n",
        "train_set = train_df\n",
        "val_set = val_df\n",
        "test_set = test_df"
      ],
      "metadata": {
        "id": "SUYVz8e0mZND"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Making Training set"
      ],
      "metadata": {
        "id": "9_7mRavvVAxG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_arrays = process_img(train_set)"
      ],
      "metadata": {
        "id": "iXLqRk_ncUTz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "## scale daisy feature\n",
        "daisy_scaler = StandardScaler()\n",
        "scaled_daisy = daisy_scaler.fit_transform(train_arrays[7])\n",
        "\n",
        "# save daisy scaler\n",
        "pickle.dump(daisy_scaler, open(pca_pickle_dir+'daisy_standardscaler.pkl', 'wb'))\n",
        "\n",
        "## scale luminance feature\n",
        "lum_scaler = StandardScaler()\n",
        "scaled_lum = lum_scaler.fit_transform(train_arrays[3])\n",
        "\n",
        "# save scaler\n",
        "pickle.dump(lum_scaler, open(pca_pickle_dir+'lum_standardscaler.pkl', 'wb'))\n",
        "\n",
        "## scale saturation feature\n",
        "sat_scaler = StandardScaler()\n",
        "scaled_sat = sat_scaler.fit_transform(train_arrays[2])\n",
        "\n",
        "# save scaler\n",
        "pickle.dump(sat_scaler, open(pca_pickle_dir+'sat_standardscaler.pkl', 'wb'))\n",
        "\n",
        "## scale hue feature\n",
        "hue_scaler = StandardScaler()\n",
        "scaled_hue = hue_scaler.fit_transform(train_arrays[1])\n",
        "\n",
        "# save scaler\n",
        "pickle.dump(hue_scaler, open(pca_pickle_dir+'hue_standardscaler.pkl', 'wb'))"
      ],
      "metadata": {
        "id": "E_10i1qe_JeS"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "RANDOM_SEED = 1234\n",
        "\n",
        "# pca daisy feature\n",
        "daisy_pca = PCA(n_components=50, random_state=RANDOM_SEED)\n",
        "X_daisy = daisy_pca.fit_transform(scaled_daisy)\n",
        "\n",
        "## save pca object\n",
        "pickle.dump(daisy_pca, open(pca_pickle_dir+'daisy_pca.pkl', 'wb'))\n",
        "\n",
        "# pca luminance feature\n",
        "lum_pca = PCA(n_components=50, random_state=RANDOM_SEED)\n",
        "X_lum = lum_pca.fit_transform(scaled_lum)\n",
        "\n",
        "## save pca object\n",
        "pickle.dump(lum_pca, open(pca_pickle_dir+'lum_pca.pkl', 'wb'))\n",
        "\n",
        "# pca saturation feature\n",
        "sat_pca = PCA(n_components=50, random_state=RANDOM_SEED)\n",
        "X_sat = sat_pca.fit_transform(scaled_sat)\n",
        "\n",
        "## save pca object\n",
        "pickle.dump(sat_pca, open(pca_pickle_dir+'sat_pca.pkl', 'wb'))\n",
        "\n",
        "# pca hue feature\n",
        "hue_pca = PCA(n_components=50, random_state=RANDOM_SEED)\n",
        "X_hue = hue_pca.fit_transform(scaled_hue)\n",
        "\n",
        "## save pca object\n",
        "pickle.dump(hue_pca, open(pca_pickle_dir+'hue_pca.pkl', 'wb'))"
      ],
      "metadata": {
        "id": "74qzuTQUA6vn"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#primary features: Daisy (7), Luminance (3), Saturation (2), Hue (1), Maybe (HOG (0))\n",
        "\n",
        "# get training data\n",
        "X = np.concatenate((X_daisy,\n",
        "                    X_lum,\n",
        "                    X_sat,\n",
        "                    X_hue), axis=1)\n"
      ],
      "metadata": {
        "id": "KgEvTXRs1h_q"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls drive/MyDrive/Berkeley/w281/Fruit-and-Vegetable-Classification/modeling/pca_datasets/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m124JY7oMDvN",
        "outputId": "8c4d1433-6df6-4030-c5d2-da7d9eb4c7bc"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "test_daisy_lum_sat_hue.csv\tvalidation_daisy_lum_sat_hue.csv\n",
            "training_daisy_lum_sat_hue.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## combine training data with labels\n",
        "X = np.concatenate((X,np.array((train_arrays[-1])).reshape(-1,1)), axis=1)\n",
        "X_df = pd.DataFrame(X)\n",
        "\n",
        "# Daisy, Luminance, Saturation, Hue\n",
        "\n",
        "X_df.to_csv(pca_dataset_dir+'training_daisy_lum_sat_hue.csv')"
      ],
      "metadata": {
        "id": "mGLku4vAZbRU"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_df.shape"
      ],
      "metadata": {
        "id": "00Nn40ciWVMv",
        "outputId": "507e45d4-5f61-43b7-df45-bed8acacc1d4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1535, 201)"
            ]
          },
          "metadata": {},
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Making Validation set"
      ],
      "metadata": {
        "id": "S0q5riZuU4df"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "validation_arrays = process_img(val_set)"
      ],
      "metadata": {
        "id": "ukNE0Pmo19-4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9f7786c3-56ea-460a-a9cb-279fbb7d8440"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing image #: 0\n",
            "Processing image #: 1\n",
            "Processing image #: 2\n",
            "Processing image #: 3\n",
            "Processing image #: 4\n",
            "Processing image #: 5\n",
            "Processing image #: 6\n",
            "Processing image #: 7\n",
            "Processing image #: 8\n",
            "Processing image #: 9\n",
            "Processing image #: 10\n",
            "Processing image #: 11\n",
            "Processing image #: 12\n",
            "Processing image #: 13\n",
            "Processing image #: 14\n",
            "Processing image #: 15\n",
            "Processing image #: 16\n",
            "Processing image #: 17\n",
            "Processing image #: 18\n",
            "Processing image #: 19\n",
            "Processing image #: 20\n",
            "Processing image #: 21\n",
            "Processing image #: 22\n",
            "Processing image #: 23\n",
            "Processing image #: 24\n",
            "Processing image #: 25\n",
            "Processing image #: 26\n",
            "Processing image #: 27\n",
            "Processing image #: 28\n",
            "Processing image #: 29\n",
            "Processing image #: 30\n",
            "Processing image #: 31\n",
            "Processing image #: 32\n",
            "Processing image #: 33\n",
            "Processing image #: 34\n",
            "Processing image #: 35\n",
            "Processing image #: 36\n",
            "Processing image #: 37\n",
            "Processing image #: 38\n",
            "Processing image #: 39\n",
            "Processing image #: 40\n",
            "Processing image #: 41\n",
            "Processing image #: 42\n",
            "Processing image #: 43\n",
            "Processing image #: 44\n",
            "Processing image #: 45\n",
            "Processing image #: 46\n",
            "Processing image #: 47\n",
            "Processing image #: 48\n",
            "Processing image #: 49\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/PIL/TiffImagePlugin.py:858: UserWarning: Corrupt EXIF data.  Expecting to read 4 bytes but only got 0. \n",
            "  warnings.warn(str(msg))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing image #: 50\n",
            "Processing image #: 51\n",
            "Processing image #: 52\n",
            "Processing image #: 53\n",
            "Processing image #: 54\n",
            "Processing image #: 55\n",
            "Processing image #: 56\n",
            "Processing image #: 57\n",
            "Processing image #: 58\n",
            "Processing image #: 59\n",
            "Processing image #: 60\n",
            "Processing image #: 61\n",
            "Processing image #: 62\n",
            "Processing image #: 63\n",
            "Processing image #: 64\n",
            "Processing image #: 65\n",
            "Processing image #: 66\n",
            "Processing image #: 67\n",
            "Processing image #: 68\n",
            "Processing image #: 69\n",
            "Processing image #: 70\n",
            "Processing image #: 71\n",
            "Processing image #: 72\n",
            "Processing image #: 73\n",
            "Processing image #: 74\n",
            "Processing image #: 75\n",
            "Processing image #: 76\n",
            "Processing image #: 77\n",
            "Processing image #: 78\n",
            "Processing image #: 79\n",
            "Processing image #: 80\n",
            "Processing image #: 81\n",
            "Processing image #: 82\n",
            "Processing image #: 83\n",
            "Processing image #: 84\n",
            "Processing image #: 85\n",
            "Processing image #: 86\n",
            "Processing image #: 87\n",
            "Processing image #: 88\n",
            "Processing image #: 89\n",
            "Processing image #: 90\n",
            "Processing image #: 91\n",
            "Processing image #: 92\n",
            "Processing image #: 93\n",
            "Processing image #: 94\n",
            "Processing image #: 95\n",
            "Processing image #: 96\n",
            "Processing image #: 97\n",
            "Processing image #: 98\n",
            "Processing image #: 99\n",
            "Processing image #: 100\n",
            "Processing image #: 101\n",
            "Processing image #: 102\n",
            "Processing image #: 103\n",
            "Processing image #: 104\n",
            "Processing image #: 105\n",
            "Processing image #: 106\n",
            "Processing image #: 107\n",
            "Processing image #: 108\n",
            "Processing image #: 109\n",
            "Processing image #: 110\n",
            "Processing image #: 111\n",
            "Processing image #: 112\n",
            "Processing image #: 113\n",
            "Processing image #: 114\n",
            "Processing image #: 115\n",
            "Processing image #: 116\n",
            "Processing image #: 117\n",
            "Processing image #: 118\n",
            "Processing image #: 119\n",
            "Processing image #: 120\n",
            "Processing image #: 121\n",
            "Processing image #: 122\n",
            "Processing image #: 123\n",
            "Processing image #: 124\n",
            "Processing image #: 125\n",
            "Processing image #: 126\n",
            "Processing image #: 127\n",
            "Processing image #: 128\n",
            "Processing image #: 129\n",
            "Processing image #: 130\n",
            "Processing image #: 131\n",
            "Processing image #: 132\n",
            "Processing image #: 133\n",
            "Processing image #: 134\n",
            "Processing image #: 135\n",
            "Processing image #: 136\n",
            "Processing image #: 137\n",
            "Processing image #: 138\n",
            "Processing image #: 139\n",
            "Processing image #: 140\n",
            "Processing image #: 141\n",
            "Processing image #: 142\n",
            "Processing image #: 143\n",
            "Processing image #: 144\n",
            "Processing image #: 145\n",
            "Processing image #: 146\n",
            "Processing image #: 147\n",
            "Processing image #: 148\n",
            "Processing image #: 149\n",
            "Processing image #: 150\n",
            "Processing image #: 151\n",
            "Processing image #: 152\n",
            "Processing image #: 153\n",
            "Processing image #: 154\n",
            "Processing image #: 155\n",
            "Processing image #: 156\n",
            "Processing image #: 157\n",
            "Processing image #: 158\n",
            "Processing image #: 159\n",
            "Processing image #: 160\n",
            "Processing image #: 161\n",
            "Processing image #: 162\n",
            "Processing image #: 163\n",
            "Processing image #: 164\n",
            "Processing image #: 165\n",
            "Processing image #: 166\n",
            "Processing image #: 167\n",
            "Processing image #: 168\n",
            "Processing image #: 169\n",
            "Processing image #: 170\n",
            "Processing image #: 171\n",
            "Processing image #: 172\n",
            "Processing image #: 173\n",
            "Processing image #: 174\n",
            "Processing image #: 175\n",
            "Processing image #: 176\n",
            "Processing image #: 177\n",
            "Processing image #: 178\n",
            "Processing image #: 179\n",
            "Processing image #: 180\n",
            "Processing image #: 181\n",
            "Processing image #: 182\n",
            "Processing image #: 183\n",
            "Processing image #: 184\n",
            "Processing image #: 185\n",
            "Processing image #: 186\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "## scale daisy feature\n",
        "scaled_val_daisy = daisy_scaler.fit_transform(validation_arrays[7])\n",
        "\n",
        "## scale luminance feature\n",
        "scaled_val_lum = lum_scaler.fit_transform(validation_arrays[3])\n",
        "\n",
        "## scale saturation feature\n",
        "scaled_val_sat = sat_scaler.fit_transform(validation_arrays[2])\n",
        "\n",
        "## scale hue feature\n",
        "scaled_val_hue = hue_scaler.fit_transform(validation_arrays[1])"
      ],
      "metadata": {
        "id": "b0M7g11vPVpY"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "RANDOM_SEED = 1234\n",
        "\n",
        "# pca daisy feature\n",
        "X_val_daisy = daisy_pca.fit_transform(scaled_val_daisy)\n",
        "\n",
        "# pca luminance feature\n",
        "X_val_lum = lum_pca.fit_transform(scaled_val_lum)\n",
        "\n",
        "# pca saturation feature\n",
        "X_val_sat = sat_pca.fit_transform(scaled_val_sat)\n",
        "\n",
        "# pca hue feature\n",
        "X_val_hue = hue_pca.fit_transform(scaled_val_hue)\n"
      ],
      "metadata": {
        "id": "giBRIif4RkXa"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#primary features: Daisy, Luminance, Saturation, Hue, Maybe (HOG)\n",
        "## get validation dataset\n",
        "X_val = np.concatenate((X_val_daisy,\n",
        "                    X_val_lum,\n",
        "                    X_val_sat,\n",
        "                    X_val_hue), axis=1)"
      ],
      "metadata": {
        "id": "sgd1FJRQVJuW"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## combine training data with labels\n",
        "X_val_ = np.concatenate((X_val,np.array((validation_arrays[-1])).reshape(-1,1)), axis=1)\n",
        "X_val_df = pd.DataFrame(X_val_)\n",
        "\n",
        "# Daisy, Luminance, Saturation, Hue\n",
        "\n",
        "X_val_df.to_csv(pca_dataset_dir+'validation_daisy_lum_sat_hue.csv')"
      ],
      "metadata": {
        "id": "FB3uJ6q9Skm4"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_val_df.shape"
      ],
      "metadata": {
        "id": "2U-BIatqWLug",
        "outputId": "cb37bbad-b7db-4a36-a2aa-8350eb2da37a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(187, 201)"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls drive/MyDrive/Berkeley/w281/Fruit-and-Vegetable-Classification/modeling/pca_datasets/"
      ],
      "metadata": {
        "id": "HChvcFfTTafK",
        "outputId": "bc6d81ad-996c-4d0b-d9f5-f52056965e0d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training_daisy_lum_sat_hue.csv\tvalidation_daisy_lum_sat_hue.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Making Testing set"
      ],
      "metadata": {
        "id": "uI95O4Q1Xgsx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_arrays = process_img(test_set)"
      ],
      "metadata": {
        "id": "Be3a3DB5Xdw5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fd4100e9-62da-4303-8551-f4fae83aa94c"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing image #: 0\n",
            "Processing image #: 1\n",
            "Processing image #: 2\n",
            "Processing image #: 3\n",
            "Processing image #: 4\n",
            "Processing image #: 5\n",
            "Processing image #: 6\n",
            "Processing image #: 7\n",
            "Processing image #: 8\n",
            "Processing image #: 9\n",
            "Processing image #: 10\n",
            "Processing image #: 11\n",
            "Processing image #: 12\n",
            "Processing image #: 13\n",
            "Processing image #: 14\n",
            "Processing image #: 15\n",
            "Processing image #: 16\n",
            "Processing image #: 17\n",
            "Processing image #: 18\n",
            "Processing image #: 19\n",
            "Processing image #: 20\n",
            "Processing image #: 21\n",
            "Processing image #: 22\n",
            "Processing image #: 23\n",
            "Processing image #: 24\n",
            "Processing image #: 25\n",
            "Processing image #: 26\n",
            "Processing image #: 27\n",
            "Processing image #: 28\n",
            "Processing image #: 29\n",
            "Processing image #: 30\n",
            "Processing image #: 31\n",
            "Processing image #: 32\n",
            "Processing image #: 33\n",
            "Processing image #: 34\n",
            "Processing image #: 35\n",
            "Processing image #: 36\n",
            "Processing image #: 37\n",
            "Processing image #: 38\n",
            "Processing image #: 39\n",
            "Processing image #: 40\n",
            "Processing image #: 41\n",
            "Processing image #: 42\n",
            "Processing image #: 43\n",
            "Processing image #: 44\n",
            "Processing image #: 45\n",
            "Processing image #: 46\n",
            "Processing image #: 47\n",
            "Processing image #: 48\n",
            "Processing image #: 49\n",
            "Processing image #: 50\n",
            "Processing image #: 51\n",
            "Processing image #: 52\n",
            "Processing image #: 53\n",
            "Processing image #: 54\n",
            "Processing image #: 55\n",
            "Processing image #: 56\n",
            "Processing image #: 57\n",
            "Processing image #: 58\n",
            "Processing image #: 59\n",
            "Processing image #: 60\n",
            "Processing image #: 61\n",
            "Processing image #: 62\n",
            "Processing image #: 63\n",
            "Processing image #: 64\n",
            "Processing image #: 65\n",
            "Processing image #: 66\n",
            "Processing image #: 67\n",
            "Processing image #: 68\n",
            "Processing image #: 69\n",
            "Processing image #: 70\n",
            "Processing image #: 71\n",
            "Processing image #: 72\n",
            "Processing image #: 73\n",
            "Processing image #: 74\n",
            "Processing image #: 75\n",
            "Processing image #: 76\n",
            "Processing image #: 77\n",
            "Processing image #: 78\n",
            "Processing image #: 79\n",
            "Processing image #: 80\n",
            "Processing image #: 81\n",
            "Processing image #: 82\n",
            "Processing image #: 83\n",
            "Processing image #: 84\n",
            "Processing image #: 85\n",
            "Processing image #: 86\n",
            "Processing image #: 87\n",
            "Processing image #: 88\n",
            "Processing image #: 89\n",
            "Processing image #: 90\n",
            "Processing image #: 91\n",
            "Processing image #: 92\n",
            "Processing image #: 93\n",
            "Processing image #: 94\n",
            "Processing image #: 95\n",
            "Processing image #: 96\n",
            "Processing image #: 97\n",
            "Processing image #: 98\n",
            "Processing image #: 99\n",
            "Processing image #: 100\n",
            "Processing image #: 101\n",
            "Processing image #: 102\n",
            "Processing image #: 103\n",
            "Processing image #: 104\n",
            "Processing image #: 105\n",
            "Processing image #: 106\n",
            "Processing image #: 107\n",
            "Processing image #: 108\n",
            "Processing image #: 109\n",
            "Processing image #: 110\n",
            "Processing image #: 111\n",
            "Processing image #: 112\n",
            "Processing image #: 113\n",
            "Processing image #: 114\n",
            "Processing image #: 115\n",
            "Processing image #: 116\n",
            "Processing image #: 117\n",
            "Processing image #: 118\n",
            "Processing image #: 119\n",
            "Processing image #: 120\n",
            "Processing image #: 121\n",
            "Processing image #: 122\n",
            "Processing image #: 123\n",
            "Processing image #: 124\n",
            "Processing image #: 125\n",
            "Processing image #: 126\n",
            "Processing image #: 127\n",
            "Processing image #: 128\n",
            "Processing image #: 129\n",
            "Processing image #: 130\n",
            "Processing image #: 131\n",
            "Processing image #: 132\n",
            "Processing image #: 133\n",
            "Processing image #: 134\n",
            "Processing image #: 135\n",
            "Processing image #: 136\n",
            "Processing image #: 137\n",
            "Processing image #: 138\n",
            "Processing image #: 139\n",
            "Processing image #: 140\n",
            "Processing image #: 141\n",
            "Processing image #: 142\n",
            "Processing image #: 143\n",
            "Processing image #: 144\n",
            "Processing image #: 145\n",
            "Processing image #: 146\n",
            "Processing image #: 147\n",
            "Processing image #: 148\n",
            "Processing image #: 149\n",
            "Processing image #: 150\n",
            "Processing image #: 151\n",
            "Processing image #: 152\n",
            "Processing image #: 153\n",
            "Processing image #: 154\n",
            "Processing image #: 155\n",
            "Processing image #: 156\n",
            "Processing image #: 157\n",
            "Processing image #: 158\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/PIL/TiffImagePlugin.py:858: UserWarning: Corrupt EXIF data.  Expecting to read 4 bytes but only got 0. \n",
            "  warnings.warn(str(msg))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing image #: 159\n",
            "Processing image #: 160\n",
            "Processing image #: 161\n",
            "Processing image #: 162\n",
            "Processing image #: 163\n",
            "Processing image #: 164\n",
            "Processing image #: 165\n",
            "Processing image #: 166\n",
            "Processing image #: 167\n",
            "Processing image #: 168\n",
            "Processing image #: 169\n",
            "Processing image #: 170\n",
            "Processing image #: 171\n",
            "Processing image #: 172\n",
            "Processing image #: 173\n",
            "Processing image #: 174\n",
            "Processing image #: 175\n",
            "Processing image #: 176\n",
            "Processing image #: 177\n",
            "Processing image #: 178\n",
            "Processing image #: 179\n",
            "Processing image #: 180\n",
            "Processing image #: 181\n",
            "Processing image #: 182\n",
            "Processing image #: 183\n",
            "Processing image #: 184\n",
            "Processing image #: 185\n",
            "Processing image #: 186\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "## scale daisy feature\n",
        "scaled_test_daisy = daisy_scaler.fit_transform(test_arrays[7])\n",
        "\n",
        "## scale luminance feature\n",
        "scaled_test_lum = lum_scaler.fit_transform(test_arrays[3])\n",
        "\n",
        "## scale saturation feature\n",
        "scaled_test_sat = sat_scaler.fit_transform(test_arrays[2])\n",
        "\n",
        "## scale hue feature\n",
        "scaled_test_hue = hue_scaler.fit_transform(test_arrays[1])"
      ],
      "metadata": {
        "id": "02mDjB-AUPgJ"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "RANDOM_SEED = 1234\n",
        "\n",
        "# pca daisy feature\n",
        "X_test_daisy = daisy_pca.fit_transform(scaled_test_daisy)\n",
        "\n",
        "# pca luminance feature\n",
        "X_test_lum = lum_pca.fit_transform(scaled_test_lum)\n",
        "\n",
        "# pca saturation feature\n",
        "X_test_sat = sat_pca.fit_transform(scaled_test_sat)\n",
        "\n",
        "# pca hue feature\n",
        "X_test_hue = hue_pca.fit_transform(scaled_test_hue)\n"
      ],
      "metadata": {
        "id": "CGyIeFQxUwTc"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_test = np.concatenate((X_test_daisy,\n",
        "                    X_test_lum,\n",
        "                    X_test_sat,\n",
        "                    X_test_hue), axis=1)"
      ],
      "metadata": {
        "id": "pcnfYW31VCck"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## combine training data with labels\n",
        "X_test_ = np.concatenate((X_test,np.array((test_arrays[-1])).reshape(-1,1)), axis=1)\n",
        "X_test_df = pd.DataFrame(X_test_)\n",
        "\n",
        "# Daisy, Luminance, Saturation, Hue\n",
        "\n",
        "X_test_df.to_csv(pca_dataset_dir+'test_daisy_lum_sat_hue.csv')"
      ],
      "metadata": {
        "id": "KGO4N_m6VUgC"
      },
      "execution_count": 60,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}